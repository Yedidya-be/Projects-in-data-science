{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe597e7f",
   "metadata": {},
   "source": [
    "# Lesson 1 - Introduction to Images and Working with them in Python\n",
    "\n",
    "Welcome! In this notebook, we will go through some basic image processing in Python and familiarize ourselves with different utilities that can be useful for any computer vision pipeline, utilities provides through libraries like numpy, napari, skimage, glob, tqdm and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433b3f2",
   "metadata": {},
   "source": [
    "### Working with Conda Environment and Installing libraries\n",
    "\n",
    "To ensure a clean and isolated working environment, we will be using [conda](https://anaconda.org), a popular package management system and environment manager for Python. Conda allows us to create and manage virtual environments with specific dependencies for our project, which can help avoid conflicts between different packages and ensure reproducibility.\n",
    "\n",
    "Here are the steps to open a Conda environment:\n",
    "\n",
    "1. Open Anaconda or Miniconda: If you have Anaconda or Miniconda installed on your machine, open the Anaconda Navigator or the Conda command prompt, respectively.\n",
    "\n",
    "\n",
    "2. Create a New Conda Environment: In the Conda command prompt, run the following command to create a new environment with a specific Python version:\n",
    "\n",
    "`conda create -n my_env python=3.9`\n",
    "\n",
    "**Replace \"my_env\" with the name you want to give to your environment, and \"python=3.8\" with the desired Python version.**\n",
    "\n",
    "3. In the Conda command prompt, run the following command to activate the environment:\n",
    "\n",
    "`conda activate my_env`\n",
    "\n",
    "4. Install libraries: With the Conda environment activated, we can now install the required packages. In the Conda command prompt, run the following commands to install NumPy, Napari, plt, and nd2:\n",
    "\n",
    "`pip install \"napari[all]\"`\n",
    "\n",
    "`conda install numpy`\n",
    "\n",
    "`conda install -c conda-forge matplotlib`\n",
    "\n",
    "`pip install nd2`\n",
    "\n",
    "5. Verify the Installation: To verify that NumPy and Napari are successfully installed, you can run the following Python code in your Jupyter notebook:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import napari\n",
    "import nd2\n",
    "import matplotlib\n",
    "```\n",
    "If there are no errors, you are all set to start working with images using NumPy and Napari in your Conda environment!\n",
    "\n",
    "With NumPy and Napari installed, you now have the necessary tools to manipulate and analyze par-seqFISH images in Python. Let's move forward and explore the exciting world of image analysis and visualization in the next sections!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf73737",
   "metadata": {},
   "source": [
    "### Downloading the Data\n",
    "To perform image analysis in this notebook, we will need to download some data from a provided link. Please follow the instructions below:\n",
    "\n",
    "1. Open the link: https://weizmann.box.com/s/mtf7jv2vr75m4nsqtmmdiktpgx4swoav in your web browser.\n",
    "\n",
    "2. Click on the \"Download\" button to download the data file to your local machine.\n",
    "\n",
    "3. Once the download is complete, locate the downloaded file on your machine. It may be in your \"Downloads\" folder or the default download location of your web browser.\n",
    "\n",
    "4. Create a folder named \"data\" in the same directory where your Jupyter Notebook is located. You can do this using the file explorer or by running the following command in a code cell in your Jupyter Notebook:\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "# Create a directory named \"data\" if it doesn't exist\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "```\n",
    "\n",
    "5. Move the downloaded data file into the \"data\" folder that you just created.\n",
    "\n",
    "6. You are now ready to access the downloaded data in your Jupyter Notebook for further image analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99203dda",
   "metadata": {},
   "source": [
    "### Images as arrays \n",
    "\n",
    "Images are represented as numpy arrays of shape (height, width, channels).\n",
    "\n",
    "![RGB image as a numpy array](asserts/image_as_array.png)\n",
    "\n",
    "<div style=\"text-align: right\"> Credit: <a href=\"https://e2eml.school/convert_rgb_to_grayscale.html\">Brandon Rohrerâ€™s Blog</a></div>\n",
    "\n",
    "\n",
    "Multiple utilities/packages exist to read images from files in Python,\n",
    "we will use `nd2.ND2File` from [nd2 library](https://pypi.org/project/nd2/).\n",
    "\n",
    "\n",
    "If you look in the directory containing this notebook, you will find a folder called data which includes some nd2 files. \n",
    "\n",
    "Let's load one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c1e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nd2\n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe120f60",
   "metadata": {},
   "source": [
    "### Extracting Image Data and Metadata\n",
    "\n",
    "Now that we have loaded the image using the \"nd2\" library, we can extract the image data and metadata from the \"img\" object. \n",
    "\n",
    "**Image Data Extraction:**\n",
    "\n",
    "To extract the image data as a NumPy array, we can use the \"asarray()\" method provided by the \"nd2\" library. The extracted image data will be a 3D NumPy array, where the first dimension represents the channel, and the second and third dimensions represent the row and column indices, respectively. Here's an example:\n",
    "\n",
    "```python\n",
    "# Extract the image data as a NumPy array\n",
    "image = img.asarray()\n",
    "```\n",
    "The resulting \"image\" variable will contain the image data as a NumPy array, which can be further processed and analyzed using various NumPy and image processing functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e949c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the image data as a NumPy array\n",
    "import numpy as np\n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511615b4",
   "metadata": {},
   "source": [
    "### Exploring Image Properties\n",
    "\n",
    "Now that we have imported the `nd2` package and loaded an image from the provided path, let's explore some properties of the image.\n",
    "\n",
    "1. **Image Shape:** To find out the shape of the image, you can simply print the `shape` attribute of the `img` object, like this:\n",
    "\n",
    "    ```python\n",
    "    print(\"Image Shape:\", img.shape)\n",
    "    ```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae80bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the shape of the image? (e.g., (height, width, channels, z axis))\n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb0cfa",
   "metadata": {},
   "source": [
    "2. **Channel Ranges:** Next, let's determine the range of intensity values for each channel in the image. You can use the `min()` and `max()` functions along with the `channels` attribute of the `img` object to obtain the minimum and maximum intensity values for each channel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb45d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the range of intensity values for each channel in the image? (e.g., Channel 1 Range: min = 0, max = 255)\n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa9a28",
   "metadata": {},
   "source": [
    "\n",
    "3. **Metadata Extraction:** Image metadata can provide valuable information about the acquisition settings, microscope parameters, and other experimental details. You can extract the metadata from the `img` object using the `metadata` attribute, like this:\n",
    "\n",
    "    ```python\n",
    "    image_metadata = img.metadata\n",
    "    ```\n",
    "\n",
    "    Please answer the following question: What information can you gather from the extracted metadata? \n",
    "\n",
    "Take a moment to explore the uploaded image and answer the questions above. Understanding the properties and metadata of the image will help us in further analysis and interpretation of the data. Feel free to refer to the `nd2` documentation for more details on working with ND2 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07e8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What information can you gather from the extracted metadata? \n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6a140",
   "metadata": {},
   "source": [
    "### Displaying Image using Matplotlib\n",
    "\n",
    "In addition to exploring the image properties, we can also visualize the image using the Matplotlib library. Matplotlib provides various functions to display images, such as `imshow()`.\n",
    "\n",
    "To display the loaded image, you can use the following code:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the first channel of the image\n",
    "channel = img.channels[0] # Choose a channel to display\n",
    "plt.imshow(img[channel], cmap='gray')\n",
    "plt.title('Image Channel: ' + channel)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "```\n",
    "This code snippet uses `imshow()` function to display the image data from a selected channel using a grayscale colormap. The `title()` function sets the title of the plot, and `colorbar()` function adds a colorbar to the plot for intensity scale.\n",
    "\n",
    "You can also customize the display properties such as `colormap`, `colorbar`, and other visual settings as needed. Matplotlib provides extensive documentation for further customization options.\n",
    "\n",
    "Please go ahead and use the above code to display the image, and experiment with different channels and visualization settings as needed. Visualizing the image can help you gain insights into the data and better understand the characteristics of the image.\n",
    "\n",
    "Note: Make sure to run the `plt.show()` function to display the plot in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2c3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86caae2b",
   "metadata": {},
   "source": [
    "### Image Slicing and Cropping\n",
    "\n",
    "Now that we have loaded the image, let's explore how to extract and manipulate regions of interest (ROI) from the image using image slicing and cropping.\n",
    "\n",
    "Image Slicing:\n",
    "\n",
    "Image slicing allows you to extract specific portions of the image by indexing the image data. You can use square brackets with colon (':') notation to specify the range of indices for each dimension. For example:\n",
    "\n",
    "```python\n",
    "# Extract a slice from the image\n",
    "image_slice = img[z, channel, start_row:end_row, start_col:end_col]\n",
    "```\n",
    "Try experimenting with different values for z, start_row, end_row, start_col, and end_col to extract and crop different regions of the image. You can also visualize the extracted or cropped regions using Matplotlib to visually inspect the results.\n",
    "\n",
    "Please go ahead and try slicing and cropping the image using the provided instructions, and feel free to ask any questions or seek clarification if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402efa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8bf9e",
   "metadata": {},
   "source": [
    "### Using Napari for Image Visualization and Analysis\n",
    "[Napari](https://napari.org/stable/) is a popular open-source Python library for visualizing and analyzing multi-dimensional image data. It provides a user-friendly interface for exploring and manipulating images in a flexible and interactive way. Let's briefly introduce Napari and then provide an exercise for you to try.\n",
    "\n",
    "Napari allows you to easily load images, visualize them in different channels, and explore various image properties. You can also apply various image processing operations, such as contrast stretching, gamma correction, and filtering, to enhance the visualization of your images. Additionally, Napari provides tools for annotating images, measuring image features, and performing region-of-interest (ROI) analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f8ebf",
   "metadata": {},
   "source": [
    "Now, let's try an exercise to load an image with multiple layers into Napari and explore some of its features. Please upload an image of your choice using the provided code snippet:\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import napari\n",
    "\n",
    "# Load the image layers using napari\n",
    "viewer = napari.Viewer() # Open napari viewer\n",
    "viewer.add_image(image_layer1, name='Channel 1') # Upload image layer 1\n",
    "viewer.add_image(image_layer2, name='Channel 2') # Upload image layer 2\n",
    "\n",
    "# Upload a label layer if available\n",
    "viewer.add_labels(label_layer, name='Labels') # Upload label layer\n",
    "```\n",
    "\n",
    "Once you have loaded the image layers into Napari, you can use the Napari viewer to interactively explore and manipulate the images. You can adjust the display properties, such as interpolation, LUT, and contrast limits, for each image layer independently. You can also use the Zoom and Pan tools to navigate and explore different regions of the images. Additionally, you can use the Labels layer to overlay segmentation masks or annotations on top of the image layers for further analysis.\n",
    "\n",
    "Try playing with the following features:\n",
    "\n",
    "**Interpolation:** Change the interpolation method used for image display to see the effect on image quality for each image layer.\n",
    "\n",
    "**LUT (Lookup Table):** Apply different lookup tables to each image layer to adjust the color mapping.\n",
    "\n",
    "**Contrast Limits:** Adjust the contrast limits for each image layer to control the display range of pixel intensities.\n",
    "\n",
    "**Zooming and Panning:** Use the Zoom and Pan tools to navigate and explore different regions of the images.\n",
    "\n",
    "**Labels Layer:** Use the Labels layer to overlay segmentation masks or annotations on top of the image layers for further analysis.\n",
    "\n",
    "Feel free to experiment with different settings and explore the capabilities of Napari for image visualization and analysis. Don't forget to save your Jupyter Notebook and share it with your peers for further discussions and collaborations!\n",
    "\n",
    "Note: If you encounter any issues or have questions while using Napari, please refer to the official Napari documentation for detailed instructions and troubleshooting tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7682aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568a99c",
   "metadata": {},
   "source": [
    "### Stacking the Z-Axis for Image Analysis\n",
    "As you may have noticed, the image data for each channel in the provided dataset consists of multiple layers along the Z-axis, representing different sections of the sample volume. This Z-stack data can be utilized in various ways to gain insights from the image data.\n",
    "\n",
    "I encourage you to explore different ways of stacking the Z-axis to generate different projections or views of the sample volume. For example, you can try averaging the Z-stack to create a maximum intensity projection (MIP) or a mean intensity projection (MIP) to visualize the overall signal distribution in the sample. Alternatively, you can select specific Z-planes or ranges to create custom views or sections of the sample volume that may be of interest for your analysis.\n",
    "\n",
    "Experimenting with different ways of stacking the Z-axis can provide valuable insights and help you better understand the data in the context of your analysis goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "238304b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "\n",
    "# Your Answer #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abf14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
